{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Transfer Learning Guide: Fine-tune Pretrained Quantum Models\n",
                "\n",
                "Save training time by starting from pretrained models.\n",
                "\n",
                "**Time:** 15-20 minutes  \n",
                "**Level:** Intermediate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## What is Transfer Learning?\n",
                "\n",
                "Transfer learning allows you to:\n",
                "1. Load a pretrained quantum model\n",
                "2. Fine-tune it on your specific data\n",
                "3. Save significant training time\n",
                "4. Often achieve better performance\n",
                "\n",
                "Think of it like starting with an experienced model rather than training from scratch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "from quantum_debugger.qml.transfer import PretrainedQNN\n",
                "from quantum_debugger.qml.qnn import QuantumNeuralNetwork\n",
                "import numpy as np\n",
                "from sklearn.datasets import make_classification\n",
                "from sklearn.model_selection import train_test_split\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Method 1: Load from Model Zoo\n",
                "\n",
                "The easiest way - use our pretrained models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pretrained model (if available in model zoo)\n",
                "# For demonstration, we'll train a base model first\n",
                "\n",
                "# Create base model\n",
                "print(\"Training base model...\")\n",
                "base_qnn = QuantumNeuralNetwork(n_qubits=4)\n",
                "base_qnn.compile(optimizer='adam', loss='mse')\n",
                "\n",
                "# Generate base training data\n",
                "X_base, y_base = make_classification(\n",
                "    n_samples=100, n_features=4, n_informative=4,\n",
                "    n_redundant=0, n_classes=2, random_state=42\n",
                ")\n",
                "\n",
                "# Train base model\n",
                "history = base_qnn.fit(X_base, y_base, epochs=20, verbose=0)\n",
                "print(f\"Base model trained. Final loss: {history['loss'][-1]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Method 2: Create Pretrained Model from Existing QNN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert to PretrainedQNN\n",
                "pretrained = PretrainedQNN.from_qnn(\n",
                "    base_qnn,\n",
                "    model_name='binary_classifier',\n",
                "    dataset='synthetic',\n",
                "    metadata={'n_qubits': 4, 'trained_epochs': 20}\n",
                ")\n",
                "\n",
                "print(\"Pretrained model created\")\n",
                "print(f\"Model info: {pretrained.get_model_info()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fine-tuning: Standard Approach\n",
                "\n",
                "Fine-tune all layers on new data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate new task data (related but different)\n",
                "X_new, y_new = make_classification(\n",
                "    n_samples=80, n_features=4, n_informative=4,\n",
                "    n_redundant=0, n_classes=2, random_state=123  # Different seed\n",
                ")\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X_new, y_new, test_size=0.25, random_state=42\n",
                ")\n",
                "\n",
                "print(f\"New task - Train: {len(X_train)}, Test: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fine-tune (all layers)\n",
                "print(\"Fine-tuning all layers...\")\n",
                "ft_history = pretrained.fine_tune(\n",
                "    X_train, y_train,\n",
                "    epochs=10,\n",
                "    freeze_layers=0,  # 0 = no freezing\n",
                "    verbose=0\n",
                ")\n",
                "\n",
                "print(f\"Fine-tuned. Final loss: {ft_history['loss'][-1]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fine-tuning: Layer Freezing\n",
                "\n",
                "Freeze early layers, only train final layers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create another pretrained model for comparison\n",
                "pretrained_frozen = PretrainedQNN.from_qnn(\n",
                "    base_qnn,\n",
                "    model_name='binary_classifier_frozen',\n",
                "    dataset='synthetic'\n",
                ")\n",
                "\n",
                "# Fine-tune with frozen layers\n",
                "print(\"Fine-tuning with 2 layers frozen...\")\n",
                "ft_frozen_history = pretrained_frozen.fine_tune(\n",
                "    X_train, y_train,\n",
                "    epochs=10,\n",
                "    freeze_layers=2,  # Freeze first 2 layers\n",
                "    verbose=0\n",
                ")\n",
                "\n",
                "print(f\"Fine-tuned (frozen). Final loss: {ft_frozen_history['loss'][-1]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Compare: From Scratch vs Transfer Learning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train from scratch for comparison\n",
                "print(\"Training from scratch...\")\n",
                "scratch_qnn = QuantumNeuralNetwork(n_qubits=4)\n",
                "scratch_qnn.compile(optimizer='adam', loss='mse')\n",
                "scratch_history = scratch_qnn.fit(X_train, y_train, epochs=10, verbose=0)\n",
                "\n",
                "print(f\"From scratch. Final loss: {scratch_history['loss'][-1]:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate all models\n",
                "models = {\n",
                "    'Transfer (All)': pretrained,\n",
                "    'Transfer (Frozen)': pretrained_frozen,\n",
                "    'From Scratch': scratch_qnn\n",
                "}\n",
                "\n",
                "results = {}\n",
                "for name, model in models.items():\n",
                "    if isinstance(model, PretrainedQNN):\n",
                "        preds = model.predict(X_test)\n",
                "    else:\n",
                "        preds = model.predict(X_test)\n",
                "    \n",
                "    pred_labels = (preds > 0.5).astype(int).flatten()\n",
                "    accuracy = np.mean(pred_labels == y_test)\n",
                "    results[name] = accuracy\n",
                "    print(f\"{name}: {accuracy:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualize Training Progress"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "# Loss comparison\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(ft_history['loss'], label='Transfer (All)', linewidth=2)\n",
                "plt.plot(ft_frozen_history['loss'], label='Transfer (Frozen)', linewidth=2)\n",
                "plt.plot(scratch_history['loss'], label='From Scratch', linewidth=2)\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.title('Training Loss Comparison')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "# Accuracy comparison\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.bar(results.keys(), results.values())\n",
                "plt.ylabel('Accuracy')\n",
                "plt.title('Final Test Accuracy')\n",
                "plt.ylim([0, 1])\n",
                "plt.grid(True, alpha=0.3, axis='y')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save and Load Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save pretrained model\n",
                "pretrained.save('my_quantum_model.pkl')\n",
                "print(\"Model saved to my_quantum_model.pkl\")\n",
                "\n",
                "# Load later\n",
                "loaded_model = PretrainedQNN.load('my_quantum_model.pkl')\n",
                "print(\"Model loaded successfully\")\n",
                "\n",
                "# Verify it works\n",
                "test_pred = loaded_model.predict(X_test[:5])\n",
                "print(f\"\\nTest predictions: {test_pred.flatten()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Best Practices\n",
                "\n",
                "### When to use Transfer Learning:\n",
                "1. **Limited data** - You have small training set\n",
                "2. **Similar tasks** - New task related to pretrained model's task\n",
                "3. **Fast prototyping** - Need quick results\n",
                "4. **Resource constrained** - Limited training time/compute\n",
                "\n",
                "### Layer Freezing Strategy:\n",
                "- **Freeze more layers** when new data is very similar to original\n",
                "- **Freeze fewer layers** when new task is quite different\n",
                "- **No freezing** when you have lots of new data\n",
                "\n",
                "### Tips:\n",
                "1. Always compare with training from scratch\n",
                "2. Experiment with different freeze levels\n",
                "3. Use lower learning rate for fine-tuning\n",
                "4. Monitor validation performance"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "Try:\n",
                "1. Use your own dataset\n",
                "2. Experiment with freeze_layers parameter\n",
                "3. Compare training times\n",
                "4. Build your own model zoo\n",
                "\n",
                "Other notebooks:\n",
                "- `01_quickstart_automl.ipynb` - AutoML basics\n",
                "- `03_hardware_deployment.ipynb` - Real quantum hardware\n",
                "- `04_advanced_optimization.ipynb` - Circuit optimization\n",
                "- `05_benchmarking_qml_vs_classical.ipynb` - Performance comparison"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}